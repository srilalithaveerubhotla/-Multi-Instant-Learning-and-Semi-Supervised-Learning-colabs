{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_1_Part_1.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOr3zYTnUzZjJ0k1DDr2opW",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/srilalithaveerubhotla/Multi-Instant-Learning-and-Semi-Supervised-Learning-colabs/blob/master/Assignment_1_Part_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yb9Cz4LOqtwU",
        "colab_type": "text"
      },
      "source": [
        "# What is Multi Instance Learning ??\n",
        "## >> Solving a classification, object detection problem When your data has partially labels for your data and those partially labelled are formed as bags which are correctly labelled\n",
        "\n",
        "# What am i Doing in this notebook ??\n",
        "## >> Explaining the State-of-the-art using MNIST Dataset\n",
        "\n",
        "# How did I approach State-of-the-art with Multi Instance Learning ??\n",
        "## I have directly made data into two bags where all the digit '1' are in one bag with few other labels which are made unknown.Used Pytorch to solve.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TndWHlMSRXys",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torchvision.models.resnet import ResNet, BasicBlock\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision.datasets import CIFAR10\n",
        "from tqdm.autonotebook import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
        "import inspect\n",
        "import time\n",
        "from torch import nn, optim\n",
        "import torch\n",
        "from torchvision.transforms import Compose, ToTensor, Normalize, Resize\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import tensorflow as tf\n",
        "import os\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "import copy\n",
        "import re\n",
        "import yaml\n",
        "import uuid\n",
        "import warnings\n",
        "from functools import partial, reduce\n",
        "from random import shuffle\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn import metrics as mtx\n",
        "from sklearn import model_selection as ms\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data.dataset import Dataset\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.models import resnet\n",
        "import torchvision.transforms as transforms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zrHIRsbnRXyy",
        "colab_type": "text"
      },
      "source": [
        "> # 1. Pretrain the MNIST and saving the weights"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29rFLpWjRXyz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data_loaders(train_batch_size, val_batch_size):\n",
        "    mnist = MNIST(download=True, train=True, root=\".\").train_data.float()\n",
        "    \n",
        "    data_transform = Compose([ Resize((224, 224)),ToTensor(), Normalize((mnist.mean()/255,), (mnist.std()/255,))])\n",
        "\n",
        "    datasettra = MNIST(download=True, root=\".\", transform=data_transform, train=True)\n",
        "    datasetval = MNIST(download=False, root=\".\", transform=data_transform, train=False)\n",
        "    print(datasettra)\n",
        "    print(datasetval)\n",
        "                            \n",
        "    train_set,a = torch.utils.data.random_split(datasettra, [11000,49000])\n",
        "    print(train_set)\n",
        "    val_set,b = torch.utils.data.random_split(datasetval, [3000,7000])\n",
        "    train_loader = DataLoader(train_set,batch_size=train_batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(val_set,batch_size=val_batch_size, shuffle=False)\n",
        "    return train_loader, val_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NvNsLr7ZRXy4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch_size = 256\n",
        "val_batch_size = 256\n",
        "\n",
        "train_loader, valid_loader = data_loaders(train_batch_size, val_batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN0FRPRRRXy7",
        "colab_type": "text"
      },
      "source": [
        "> ### 1.1 define model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "agRJjd3ERXy8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Mnist_ResNet(ResNet):\n",
        "    def __init__(self):\n",
        "        super(Mnist_ResNet, self).__init__(BasicBlock, [2, 2, 2, 2], num_classes=10)\n",
        "        self.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return torch.softmax(super(Mnist_ResNet, self).forward(x), dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6hec1kLiRXy_",
        "colab_type": "text"
      },
      "source": [
        "> ### 1.2 helper function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TIF_Zk8MRXy_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculatemetric(metric_fn, true_y, pred_y):\n",
        "    if \"average\" in inspect.getfullargspec(metric_fn).args:\n",
        "        return metric_fn(true_y, pred_y, average=\"macro\")\n",
        "    else:\n",
        "        return metric_fn(true_y, pred_y)\n",
        "    \n",
        "def printscores(p, r, f1, a, batch_size):\n",
        "    for name, scores in zip((\"precision\", \"recall\", \"F1\", \"accuracy\"), (p, r, f1, a)):\n",
        "        print(f\"\\t{name.rjust(14, ' ')}: {sum(scores)/batch_size:.4f}\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UXy8m98wmg2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = MnistResNet()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFTskAa7RXzC",
        "colab_type": "text"
      },
      "source": [
        "> ### 1.3 train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2DfCFxkIRXzD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "start_ts = time.time()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "# model:\n",
        "model = Mnist_ResNet().to(device)\n",
        "\n",
        "# params you need to specify:\n",
        "epochs = 5\n",
        "train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n",
        "loss_function = nn.CrossEntropyLoss()         # loss function, cross entropy works well for multi-class problems\n",
        "\n",
        "# optimizer\n",
        "optimizer = optim.Adadelta(model.parameters())\n",
        "\n",
        "\n",
        "losses = []\n",
        "batches = len(train_loader)\n",
        "val_batches = len(val_loader)\n",
        "\n",
        "# loop for every epoch (training + evaluation)\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    # progress bar \n",
        "    progress = tqdm(enumerate(train_loader), desc=\"Loss: \", total=batches)\n",
        "\n",
        "    # ----------------- TRAINING  -------------------- \n",
        "    # set model to training\n",
        "    model.train()\n",
        "    \n",
        "    for i, data in progress:\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        # training step for single batch\n",
        "        model.zero_grad() # to make sure that all the grads are 0 \n",
        "        \"\"\"\n",
        "        model.zero_grad() and optimizer.zero_grad() are the same \n",
        "        IF all your model parameters are in that optimizer. \n",
        "        I found it is safer to call model.zero_grad() to make sure all grads are zero, \n",
        "        e.g. if you have two or more optimizers for one model.\n",
        "\n",
        "        \"\"\"\n",
        "        outputs = model(X)                     # forward\n",
        "        loss = loss_function(outputs, y)       # get loss\n",
        "        loss.backward()                        # accumulates the gradient (by addition) for each parameter.\n",
        "        optimizer.step()                       # performs a parameter update based on the current gradient \n",
        "\n",
        "        # getting training quality data\n",
        "        current_loss = loss.item()\n",
        "        total_loss += current_loss\n",
        "\n",
        "        # updating progress bar\n",
        "        progress.set_description(\"Loss: {:.4f}\".format(total_loss/(i+1)))\n",
        "        \n",
        "    # releasing unceseccary memory in GPU\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    # ----------------- VALIDATION  ----------------- \n",
        "    val_losses = 0\n",
        "    precision, recall, f1, accuracy = [], [], [], []\n",
        "    \n",
        "    # set model to evaluating (testing)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "            X, y = data[0].to(device), data[1].to(device)\n",
        "\n",
        "            outputs = model(X)                                    # this gets the prediction from the network\n",
        "\n",
        "            val_losses += loss_function(outputs, y)\n",
        "\n",
        "            predicted_classes = torch.max(outputs, 1)[1]          # get class from network's prediction\n",
        "            \n",
        "            # calculate P/R/F1/A metrics for batch\n",
        "            for acc, metric in zip((precision, recall, f1, accuracy), \n",
        "                                   (precision_score, recall_score, f1_score, accuracy_score)):\n",
        "                acc.append(\n",
        "                    calculatemetric(metric, y.cpu(), predicted_classes.cpu())\n",
        "                )\n",
        "          \n",
        "    print(f\"Epoch {epoch+1}/{epochs}, training loss: {total_loss/batches}, validation loss: {val_losses/val_batches}\")\n",
        "    printscores(precision, recall, f1, accuracy, val_batches)\n",
        "    losses.append(total_loss/batches) # for plotting learning curve\n",
        "print(f\"Training time: {time.time()-start_ts}s\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLBdjmDqRXzH",
        "colab_type": "text"
      },
      "source": [
        "> ### 1.4 save the model for the next steps"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYqDIkGYRXzI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.save(model.state_dict(), 'mnist_state.pt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1a01U9RRXzM",
        "colab_type": "text"
      },
      "source": [
        "> # 2. Data Generation( creating into bags)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNkjjZ9HRXzN",
        "colab_type": "text"
      },
      "source": [
        "### 2.1 load the mnist dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Un8RQ1XwRXzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.cifar10.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f-wQsK3bRXzQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sOik6ECnRXzS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_train = x_train[:50001] \n",
        "y_train = y_train[:50001]\n",
        "x_test = x_test[:1000]\n",
        "y_test = y_test[:1000]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cU36al8RXzW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Making sure that the values are float so that we can get decimal points after division\n",
        "x_train = x_train.astype('float32')\n",
        "x_test = x_test.astype('float32')\n",
        "\n",
        "# Normalizing the RGB codes by dividing it to the max RGB value.\n",
        "x_train /= 255\n",
        "x_test /= 255\n",
        "print('x_train shape:', x_train.shape)\n",
        "print('Number of images in x_train', x_train.shape[0])\n",
        "print('Number of images in x_test', x_test.shape[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J6ruk_QcRXza",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "instance_index_label = [(i, y_train[i]) for i in range(x_train.shape[0])]\n",
        "instance_index_label_test = [(i, y_test[i]) for i in range(x_test.shape[0])]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LUEvnMZBRXzd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# find the index if label is 1\n",
        "find_index = [instance_index_label[i][0] for i in range(len(instance_index_label)) if instance_index_label[i][1]==1]\n",
        "# find the index if label is 1\n",
        "find_index_test = [instance_index_label_test[i][0] for i in range(len(instance_index_label_test))\n",
        "                   if instance_index_label_test[i][1]==1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4DTEYeoRXzg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('index:', instance_index_label[0][0])         #index\n",
        "print('label:', instance_index_label[0][1])         #label"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s52K4K12RXzj",
        "colab_type": "text"
      },
      "source": [
        "> ### 2.3 load pretrained model which we saved previously"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-V1xQ-1RXzj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torchvision.models.resnet import ResNet, BasicBlock\n",
        "class MnistResNet(ResNet):\n",
        "    def __init__(self):\n",
        "        super(Mnist_ResNet(ResidualBlock, [2, 2, 2]))\n",
        "        self.conv1 = torch.nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return torch.softmax(super(MnistResNet, self).forward(x), dim=-1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "bUnyefqtRXzn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Mnist_ResNet()\n",
        "model.load_state_dict(torch.load('mnist_state.pt'))\n",
        "body = nn.Sequential(*list(model.children()))\n",
        "# extract the last layer\n",
        "model = body[:9]\n",
        "# the model we will use\n",
        "model.eval()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ygk4RQkZRXzq",
        "colab_type": "text"
      },
      "source": [
        "> ### 2.4 get features"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evgbg4kZRXzq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch_size = 1\n",
        "val_batch_size = 1\n",
        "train_loader, val_loader = get_data_loaders(train_batch_size, val_batch_size)\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "# optimizer adadelta\n",
        "optimizer = optim.Adadelta(model.parameters())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvb_rmZgRXzt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "losses = []\n",
        "batches = len(train_loader)\n",
        "val_batches = len(val_loader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SURVx-FyRXzw",
        "colab_type": "text"
      },
      "source": [
        "> #### 2.4.1 get features for train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_EXbMMBkRXzx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# loop for every epoch (training + evaluation)\n",
        "meta_table = dict()\n",
        "feature_result = []\n",
        "\n",
        "# progress bar\n",
        "progress = tqdm(enumerate(train_loader), desc=\"Loss: \", total=batches)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for i, data in progress:\n",
        "    if i==10001:  #shreyus\n",
        "        break\n",
        "    X, y = data[0], data[1]\n",
        "    # training step for single batch\n",
        "    model.zero_grad()\n",
        "    outputs = model(X)\n",
        "    feature_result.append(outputs.reshape(-1).tolist())\n",
        "    meta_table[i] = outputs.reshape(-1).tolist()\n",
        "    \n",
        "feature_array = np.array(feature_result)\n",
        "np.save('feature_array_full',feature_array )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jfUEj8IcRXzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load\n",
        "feature_array = np.load('/content/feature_array_full.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WZgcD3IkRXz2",
        "colab_type": "text"
      },
      "source": [
        "> #### 2.4.2 Get features for test dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dphX27vRXz2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "meta_t_table = dict()\n",
        "feature_t_result = []\n",
        "\n",
        "# progress bar code \n",
        "progress = tqdm(enumerate(val_loader), desc=\"Loss: \", total=batches)\n",
        "\n",
        "model.eval()\n",
        "\n",
        "for i, data in progress:\n",
        "    if i==2000: #srilalitha\n",
        "        break\n",
        "    X, y = data[0], data[1]\n",
        "    # training step for single batch\n",
        "    model.zero_grad()\n",
        "    outputs_t = model(X)\n",
        "    feature_t_result.append(outputs_t.reshape(-1).tolist())\n",
        "    meta_t_table[i] = outputs_t.reshape(-1).tolist()\n",
        "\n",
        "feature_test_array = np.array(feature_t_result)\n",
        "# save \n",
        "np.save('feature_test_array_full',feature_test_array )\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSSRIuQVRXz5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#load the saved data\n",
        "feature_test_array = np.load('/content/feature_test_array_full.npy', allow_pickle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CjHUvMp8RXz-",
        "colab_type": "text"
      },
      "source": [
        "> ### 2.5 generate data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4n_SKf7sRXz-",
        "colab_type": "text"
      },
      "source": [
        "> #### 2.5.1 generate data for train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsNLW5SNRXz_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from typing import List, Dict, Tuple\n",
        "def data_gen(instance_index_label: List[Tuple]) -> List[Dict]:\n",
        "    \"\"\"\n",
        "    bags: {key1: [ind1, ind2, ind3],\n",
        "           key2: [ind1, ind2, ind3, ind4, ind5],\n",
        "           ... }\n",
        "    bag_lbls:\n",
        "        {key1: 0,\n",
        "         key2: 1,\n",
        "         ... }\n",
        "    \"\"\"\n",
        "    bag_size = np.random.randint(3,7,size=(len(instance_index_label))//5)\n",
        "    print(len(instance_index_label))\n",
        "    data_cp = copy.copy(instance_index_label)\n",
        "    np.random.shuffle(data_cp)\n",
        "    bags = {}\n",
        "    bags_per_instance_labels = {}\n",
        "    bags_labels = {}\n",
        "  \n",
        "    for bag_ind, size in enumerate(bag_size):\n",
        "        bags[bag_ind] = []\n",
        "        bags_per_instance_labels[bag_ind] = []\n",
        "        try:\n",
        "            for _ in range(size):\n",
        "                inst_ind, lbl = data_cp.pop()\n",
        "                bags[bag_ind].append(inst_ind)\n",
        "                # simplfy, just use a temporary variable instead of bags_per_instance_labels\n",
        "                bags_per_instance_labels[bag_ind].append(lbl)\n",
        "            bags_labels[bag_ind] = bag_label_from_instance_labels(bags_per_instance_labels[bag_ind])\n",
        "        except:\n",
        "            break\n",
        "    return bags, bags_labels\n",
        "\n",
        "def bag_labelfrom_instance_labels(instance_labels):\n",
        "    return int(any(((x==1) for x in instance_labels)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElSmGIwURX0C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bag_indices, bag_labels = data_gen(instance_index_label)\n",
        "#print(feature_array)\n",
        "\n",
        "bag_features = {kk: torch.Tensor(feature_array[inds]) for kk, inds in bag_indices.items()}\n",
        "# for inds in bag_indices.items():\n",
        "#   for kk in range(torch.Tensor(feature_array[inds])):\n",
        "#     print(kk)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTf5GcC5RX0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# save\n",
        "import pickle\n",
        "pickle.dump(bag_indices, open( \"bag_indices\", \"wb\" ) )\n",
        "pickle.dump(bag_labels, open( \"bag_labels\", \"wb\" ) )\n",
        "pickle.dump(bag_features, open( \"bag_features\", \"wb\" ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oC1ApRe0RX0H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pickle\n",
        "bag_indices = pickle.load( open( \"bag_indices\", \"rb\" ) )\n",
        "bag_labels = pickle.load( open( \"bag_labels\", \"rb\" ) )\n",
        "bag_features = pickle.load( open( \"bag_features\", \"rb\" ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9kyX7Kv2RX0J",
        "colab_type": "text"
      },
      "source": [
        "> #### 2.5.2 generate data for testsets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6LQheGSWRX0K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bag_t_indices, bag_t_labels = data_gen(instance_index_label_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g1XvSUvBRX0M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bag_t_features = {kk: torch.Tensor(feature_test_array[inds]) for kk, inds in bag_t_indices.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCmNsKXPRX0R",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pickle.dump(bag_t_indices, open( \"bag_t_indices\", \"wb\" ) )\n",
        "pickle.dump(bag_t_labels, open( \"bag_t_labels\", \"wb\" ) )\n",
        "pickle.dump(bag_t_features, open( \"bag_t_features\", \"wb\" ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k79L4wKRX0U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bag_t_indices = pickle.load( open( \"bag_t_indices\", \"rb\" ) )\n",
        "bag_t_labels = pickle.load( open( \"bag_t_labels\", \"rb\" ) )\n",
        "bag_t_features = pickle.load( open( \"bag_t_features\", \"rb\" ) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cZZHo97AMYbo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! cd /content\n",
        "!pwd"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RALg2EiIRX0X",
        "colab_type": "text"
      },
      "source": [
        "> # 3. Multiple Instance Learning begins here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkiZRof5RX0Y",
        "colab_type": "text"
      },
      "source": [
        "> ### 3.1 Prepare data for modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IqpoHHg8RX0Y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "class Transform_data(Dataset):\n",
        "    \"\"\"\n",
        "    We want to 1. pad tensor 2. transform the data to the size that fits in the input size.\n",
        "    \n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, data, transform=None):\n",
        "        self.transform = transform\n",
        "        self.data = data\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        tensor = self.data[index][0]\n",
        "        if self.transform is not None:\n",
        "            tensor = self.transform(tensor)\n",
        "        return (tensor, self.data[index][1])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N_5Ea-s8RX0a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_data = [(bag_features[i],bag_labels[i]) for i in range(len(bag_features))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_9clqjPRX0d",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bag_features[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Aw63WSIHRX0g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def pad_tensor(data:list, max_number_instance) -> list:\n",
        "    \"\"\"\n",
        "    Since our bag has different sizes, we need to pad each tensor to have the same shape (max: 7).\n",
        "    We will look through each one instance and look at the shape of the tensor, and then we will pad 7-n \n",
        "    to the existing tensor where n is the number of instances in the bag.\n",
        "    The function will return a padded data set.\"\"\"\n",
        "    new_data = []\n",
        "    for bag_index in range(len(data)):\n",
        "        tensor_size = len(data[bag_index][0])\n",
        "        pad_size = max_number_instance - tensor_size\n",
        "        p2d = (0,0, 0, pad_size)\n",
        "        padded = nn.functional.pad(data[bag_index][0], p2d, 'constant', 0)\n",
        "        new_data.append((padded, data[bag_index][1]))\n",
        "    return new_data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xltfp6cORX0j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_number_instance = 7\n",
        "padded_train = pad_tensor(train_data, max_number_instance) #srilalitha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "abc5H9aLRX0l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = [(bag_t_features[i],bag_t_labels[i]) for i in range(len(bag_t_features))]\n",
        "padded_test = pad_tensor(test_data, max_number_instance)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X8KE8zIIRX0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_data_loaders(train_data, test_data, train_batch_size, val_batch_size):\n",
        "    train_loader = DataLoader(train_data, batch_size=train_batch_size, shuffle=True)\n",
        "    val_loader = DataLoader(test_data, batch_size=val_batch_size, shuffle=False)\n",
        "    return train_loader, val_loader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EqQJ_RoxRX0r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_loader,valid_loader = get_data_loaders(padded_train, padded_test, 1, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mf6Sb2zRX0y",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_batch_size = 1\n",
        "val_batch_size = 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3wwcA92kRX00",
        "colab_type": "text"
      },
      "source": [
        "> ### 3.2 Define model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XkF-uJzRRX01",
        "colab_type": "text"
      },
      "source": [
        "> #### 3.2.1 Linear model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NehLIUOCRX02",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class linear(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n=7*512, n_out=1, dropout=0.2):\n",
        "        super(linear, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(n, n_out)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        z = self.linear1(x)\n",
        "        y_pred = torch.sigmoid(z)\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aX_wkz7_RX08",
        "colab_type": "text"
      },
      "source": [
        "> #### 3.2.2 NN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rJ2qA5t1RX09",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n=7*512, n_mid = 7168, n_out=1, dropout=0.2):\n",
        "        super(NN, self).__init__()\n",
        "        self.linear1 = torch.nn.Linear(n, n_mid)\n",
        "        self.linear2 = torch.nn.Linear(n_mid, n_out)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.non_linearity = torch.nn.LeakyReLU()\n",
        "        \n",
        "    def forward(self, x):\n",
        "        z = self.linear1(x)\n",
        "        z = self.non_linearity(z)\n",
        "        z = self.dropout(z)\n",
        "        z = self.linear2(z)\n",
        "        y_pred = torch.sigmoid(z)\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NeNk9XFuRX1C",
        "colab_type": "text"
      },
      "source": [
        "> #### 3.3.3 Multiinstancelearning nn model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VwnNY67yRX1C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class NoisyAnd(torch.nn.Module):\n",
        "    def __init__(self, a=10, dims=[0]):\n",
        "        super(NoisyAnd, self).__init__()\n",
        "        self.a = a\n",
        "        self.b = torch.nn.Parameter(torch.tensor(0.01))\n",
        "        self.dims =dims\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "    def forward(self, x):\n",
        "        mean = torch.mean(x, self.dims, False)\n",
        "        res = (self.sigmoid(self.a * (mean - self.b)) - self.sigmoid(-self.a * self.b)) / (\n",
        "              self.sigmoid(self.a * (1 - self.b)) - self.sigmoid(-self.a * self.b))\n",
        "        return res\n",
        "    \n",
        "\n",
        "class MILNN(torch.nn.Module):\n",
        "\n",
        "    def __init__(self, n=7*512,  n_mid=7168, n_out=1, \n",
        "                 n_inst=None, dropout=0.1,\n",
        "                 noisy_a=4,\n",
        "                 agg = NoisyAnd(a=4, dims=[0]),\n",
        "                ):\n",
        "        super(MIL_NN, self).__init__()\n",
        "        if agg is None:\n",
        "            agg = NoisyAnd(a=noisy_a, dims=[0])\n",
        "        if n_inst is None:\n",
        "            self.mdl_instance = agg\n",
        "            n_inst = n\n",
        "        else:\n",
        "            self.mdl_instance = nn.Sequential(\n",
        "                            nn.Linear(n, n_inst),\n",
        "                            nn.LeakyReLU(),\n",
        "                            agg,\n",
        "                            )\n",
        "        if n_mid == 0:\n",
        "            self.mdl_bag = LogisticRegression(n_inst, n_out)\n",
        "        else:\n",
        "            self.mdl_bag = NN(n_inst, n_mid, n_out, dropout=dropout)\n",
        "        \n",
        "    def forward(self, bag_feature):\n",
        "\n",
        "        y_pred = self.mdl_bag(bag_feature)\n",
        "        return y_pred"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VtOjcTAMRX1G",
        "colab_type": "text"
      },
      "source": [
        "> #### 3.3.4 helper function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z8Axz6VuRX1G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def calculatemetric(metric_fn, true_y, pred_y):\n",
        "\n",
        "    if \"average\" in inspect.getfullargspec(metric_fn).args:\n",
        "        return metric_fn(true_y, pred_y, average=\"macro\")\n",
        "    else:\n",
        "        return metric_fn(true_y, pred_y)\n",
        "    \n",
        "def printscores(p, r, f1, a, batch_size):\n",
        "\n",
        "  \\\n",
        "    for name, scores in zip((\"precision\", \"recall\", \"F1\", \"accuracy\"), (p, r, f1, a)):\n",
        "        print(f\"\\t{name.rjust(14, ' ')}: {sum(scores)/batch_size:.4f}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "144NLzxJRX1J",
        "colab_type": "text"
      },
      "source": [
        "> # 4. Train & Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yko8sAGWRX1J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "start_ts = time.time()\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "lr0 = 1e-4\n",
        "\n",
        "# model:\n",
        "model = MILNN().to(device)\n",
        "\n",
        "# params you need to specify below\n",
        "epochs = 10\n",
        "train_loader, val_loader = get_data_loaders(padded_train, padded_test, 1, 1)\n",
        "loss_function = torch.nn.BCELoss(reduction='mean')      # loss function: BCELoss works well for binary class problems\n",
        "\n",
        "\n",
        "#optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr0, momentum=0.9)\n",
        "\n",
        "losses = []\n",
        "batches = len(train_loader)\n",
        "val_batches = len(val_loader)\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    total_loss = 0\n",
        "\n",
        "    # progress bar\n",
        "    progress = tqdm(enumerate(train_loader), desc=\"Loss: \", total=batches)\n",
        "\n",
        "    # ----------------- TRAINING starts here  -------------------- \n",
        "  \n",
        "    model.train()\n",
        "    for i, data in progress:\n",
        "        X, y = data[0].to(device), data[1].to(device)\n",
        "        X = X.reshape([1,7*512])\n",
        "        y = y.type(torch.cuda.FloatTensor)\n",
        "        # training step for single batch\n",
        "        model.zero_grad() \n",
        "        \"\"\"\n",
        "        model.zero_grad() and optimizer.zero_grad() are the same \n",
        "        IF all your model parameters are in that optimizer. \n",
        "        I found it is safer to call model.zero_grad() to make sure all grads are zero, \n",
        "        e.g. if you have two or more optimizers for one model.\n",
        "\n",
        "        \"\"\"\n",
        "        outputs = model(X)                             # forward pass\n",
        "        loss = loss_function(outputs, y)               # get loss function\n",
        "        loss.backward()                                # accumulates the gradient \n",
        "        optimizer.step()                               # performs a parameter update based on the current gradient \n",
        "\n",
        "        # getting training quality data\n",
        "        current_loss = loss.item()\n",
        "        total_loss += current_loss\n",
        "\n",
        "        # updating progress bar\n",
        "        progress.set_description(\"Loss: {:.4f}\".format(total_loss/(i+1)))\n",
        "        \n",
        "    # releasing unceseccary memory in GPU\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.empty_cache()\n",
        "    \n",
        "    # ----------------- VALIDATION  ----------------- \n",
        "    val_losses = 0\n",
        "    precision, recall, f1, accuracy = [], [], [], []\n",
        "    \n",
        "    # set model to evaluating (testing)\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, data in enumerate(val_loader):\n",
        "            X, y = data[0].to(device), data[1].to(device)\n",
        "            X = X.reshape([1,7*512])\n",
        "            y = y.type(torch.cuda.FloatTensor)\n",
        "            outputs = model(X)                         # this get's the prediction from the network\n",
        "            prediced_classes =outputs.detach().round()\n",
        "            val_losses += loss_function(outputs, y)\n",
        "            \n",
        "            # calculate P/R/F1/A metrics for batch\n",
        "            for acc, metric in zip((precision, recall, f1, accuracy), \n",
        "                                   (precision_score, recall_score, f1_score, accuracy_score)):\n",
        "                acc.append(\n",
        "                    calculatemetric(metric, y.cpu(), prediced_classes.cpu())\n",
        "                )\n",
        "          \n",
        "    print(f\"Epoch {epoch+1}/{epochs}, training loss: {total_loss/batches}, validation loss: {val_losses/val_batches}\")\n",
        "    printscores(precision, recall, f1, accuracy, val_batches)\n",
        "    losses.append(total_loss/batches)                  # for plotting learning curve\n",
        "print(f\"Training time: {time.time()-start_ts}s\") #srilalitha"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvHBRl1zRX1M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lOjITF8qRX1O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TKYZziMlRX1U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}